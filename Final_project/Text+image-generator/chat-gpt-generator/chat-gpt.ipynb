{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve input for experimental design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "with open('all_scores.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT functions to retrieve text and image based on all_scores.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_GPT(text_prompt):\n",
    "    \"\"\"\n",
    "    Creates a new ChatGPT output, based on certain rules defined in the global variable \"standard_rules\".\n",
    "    It clears the conversation history and add the new list items to it (starting a new chat).\n",
    "\n",
    "    Input\n",
    "    A text prompt that is meant for ChatGPT in string\n",
    "\n",
    "    Returns\n",
    "    ChatGPT output in a string\n",
    "\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": \"Create the output without any markdown or markup\"}]\n",
    "    messages.append({\"role\": \"user\", \"content\": text_prompt})\n",
    "\n",
    "    new = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages\n",
    "            )\n",
    "\n",
    "    # only get the output message \n",
    "    output = new.choices[0].message.content\n",
    "\n",
    "    return output\n",
    "\n",
    "def generate_image_GPT(text_prompt):\n",
    "    \"\"\"\n",
    "    Creates a new DALLE-3 output, based on certain rules defined in the global variable \"standard_rules\".\n",
    "\n",
    "    Input\n",
    "    A text prompt that is meant for ChatGPT in string\n",
    "\n",
    "    Returns\n",
    "    Image URL (online for an hour)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.images.generate(\n",
    "                model=\"dall-e-3\",\n",
    "                prompt=text_prompt,\n",
    "                size=\"1024x1024\",\n",
    "                quality=\"standard\",\n",
    "                n=1\n",
    "            )\n",
    "\n",
    "    # get image URL\n",
    "    image_url = response.data[0].url\n",
    "\n",
    "    return image_url\n",
    "\n",
    "\n",
    "def output(data):\n",
    "    amount_stages = data['stages']\n",
    "    for i in range(amount_stages):\n",
    "        i += 1\n",
    "        print(f\"log - stage: {i}\")\n",
    "\n",
    "        prompts = data[f'stage_{i}']['prompts']['text_prompt']\n",
    "        for cat, prompt in prompts.items():\n",
    "            # textual output\n",
    "            print(f\"log - category: {cat}, creating text\")\n",
    "            text_output = generate_text_GPT(prompt)\n",
    "            data[f'stage_{i}']['output_text'][f'{cat}'] = text_output\n",
    "            \n",
    "            # sentiment analysis\n",
    "            print('log - creating sentiment')\n",
    "            blob = TextBlob(text_output, analyzer=NaiveBayesAnalyzer())\n",
    "            data[f'stage_{i}']['sentiment'][f'{cat}'] = blob.sentiment\n",
    "\n",
    "        prompts = data[f'stage_{i}']['prompts']['image_prompt']\n",
    "        for cat, prompt in prompts.items():\n",
    "            # image output\n",
    "            print(f\"log - category: {cat}, creating image\")\n",
    "            image_url = generate_image_GPT(prompt)\n",
    "            image_output = requests.get(image_url).content\n",
    "            with open(f\"images2/S{i}{cat}.png\", \"wb\") as file:\n",
    "                file.write(image_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log - stage: 1\n",
      "log - category: B, creating text\n",
      "log - creating sentiment\n",
      "log - category: PHA, creating text\n",
      "log - creating sentiment\n",
      "log - category: NHA, creating text\n",
      "log - creating sentiment\n",
      "log - category: PLA, creating text\n",
      "log - creating sentiment\n",
      "log - category: NLA, creating text\n",
      "log - creating sentiment\n",
      "log - category: B, creating image\n",
      "log - category: PHA, creating image\n",
      "log - category: NHA, creating image\n",
      "log - category: PLA, creating image\n",
      "log - category: NLA, creating image\n",
      "log - stage: 2\n",
      "log - category: B, creating text\n",
      "log - creating sentiment\n",
      "log - category: PHA, creating text\n",
      "log - creating sentiment\n",
      "log - category: NHA, creating text\n",
      "log - creating sentiment\n",
      "log - category: PLA, creating text\n",
      "log - creating sentiment\n",
      "log - category: NLA, creating text\n",
      "log - creating sentiment\n",
      "log - category: B, creating image\n",
      "log - category: PHA, creating image\n",
      "log - category: NHA, creating image\n",
      "log - category: PLA, creating image\n",
      "log - category: NLA, creating image\n",
      "log - stage: 3\n",
      "log - category: B, creating text\n",
      "log - creating sentiment\n",
      "log - category: PHA, creating text\n",
      "log - creating sentiment\n",
      "log - category: NHA, creating text\n",
      "log - creating sentiment\n",
      "log - category: PLA, creating text\n",
      "log - creating sentiment\n",
      "log - category: NLA, creating text\n",
      "log - creating sentiment\n",
      "log - category: B, creating image\n",
      "log - category: PHA, creating image\n",
      "log - category: NHA, creating image\n",
      "log - category: PLA, creating image\n",
      "log - category: NLA, creating image\n",
      "log - stage: 4\n",
      "log - category: B, creating text\n",
      "log - creating sentiment\n",
      "log - category: PHA, creating text\n",
      "log - creating sentiment\n",
      "log - category: NHA, creating text\n",
      "log - creating sentiment\n",
      "log - category: PLA, creating text\n",
      "log - creating sentiment\n",
      "log - category: NLA, creating text\n",
      "log - creating sentiment\n",
      "log - category: B, creating image\n",
      "log - category: PHA, creating image\n",
      "log - category: NHA, creating image\n",
      "log - category: PLA, creating image\n",
      "log - category: NLA, creating image\n"
     ]
    }
   ],
   "source": [
    "# Run functions\n",
    "output(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FAIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
